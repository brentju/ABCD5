{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Sex Assigned at Birth with Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from tqdm import tqdm\n",
    "from abcd.local.paths import output_path\n",
    "from abcd.data.read_data import get_subjects_events_sf, subject_cols_to_events\n",
    "import abcd.data.VARS as VARS\n",
    "from abcd.data.define_splits import SITES, save_restore_sex_fmri_splits\n",
    "from abcd.data.divide_with_splits import divide_events_by_splits\n",
    "from abcd.data.var_tailoring.normalization import normalize_var\n",
    "from abcd.data.pytorch.get_dataset import PandasDataset\n",
    "\n",
    "#regresssion-specific imports\n",
    "from abcd.models.regression.MLPRegressor import MLPRegressor, LinearRegressor, MLPRegressorCustom\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from abcd.training.RegressorTrainer import RegressorTrainer\n",
    "\n",
    "#plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import pygal\n",
    "from abcd.plotting.pygal.rendering import display_html\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from abcd.plotting.seaborn.confusion_matrix import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abcd.analysis.regression import preprocess, train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucketing_scheme = \"sex\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Determine device for training (TODO: figure out why doesn't work with mps)\n",
    "device = \"cpu\" #(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(\"Using {} device\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 9632 subjects and 18808 visits with imaging\n",
      "Leaving baseline visits, we have 9085 events\n",
      "\n",
      "There are 9085 visits after adding the target and removing NAs\n",
      "\n",
      "Created splits\n",
      "Nr. events: 7063 train, 1738 val, 284 test\n",
      "Normalized targets with respect to min and max of training set. New target column containing normalized data: kbi_sex_assigned_at_birth_norm\n",
      "\n",
      "Created dataloaders\n",
      "Shape and datatype of X: torch.Size([64, 453]), torch.float32\n",
      "Shape and datatype of y: torch.Size([64]), torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carolinezanze/Desktop/ABCD5/abcd/data/var_tailoring/normalization.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[y_new_name] = (df[y]-y_min)/(y_max-y_min)\n",
      "/Users/carolinezanze/Desktop/ABCD5/abcd/data/var_tailoring/normalization.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[y_new_name] = (df[y]-y_min)/(y_max-y_min)\n",
      "/Users/carolinezanze/Desktop/ABCD5/abcd/data/var_tailoring/normalization.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[y_new_name] = (df[y]-y_min)/(y_max-y_min)\n",
      "/Users/carolinezanze/Desktop/ABCD5/abcd/data/var_tailoring/normalization.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[y_new_name] = (df[y]-y_min)/(y_max-y_min)\n",
      "/Users/carolinezanze/Desktop/ABCD5/abcd/data/var_tailoring/normalization.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[y_new_name] = (df[y]-y_min)/(y_max-y_min)\n",
      "/Users/carolinezanze/Desktop/ABCD5/abcd/data/var_tailoring/normalization.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[y_new_name] = (df[y]-y_min)/(y_max-y_min)\n"
     ]
    }
   ],
   "source": [
    "dataloaders, events_train, events_id_test, events_ood_test, feature_cols = preprocess('kbi_sex_assigned_at_birth', ['fmri', 'smri'], ood_site_num=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_subject_id</th>\n",
       "      <th>interview_date</th>\n",
       "      <th>eventname</th>\n",
       "      <th>interview_age</th>\n",
       "      <th>rsfmri_c_ngd_ad_ngd_ad</th>\n",
       "      <th>rsfmri_c_ngd_ad_ngd_cgc</th>\n",
       "      <th>rsfmri_c_ngd_ad_ngd_ca</th>\n",
       "      <th>rsfmri_c_ngd_ad_ngd_dt</th>\n",
       "      <th>rsfmri_c_ngd_ad_ngd_dla</th>\n",
       "      <th>rsfmri_c_ngd_ad_ngd_fo</th>\n",
       "      <th>...</th>\n",
       "      <th>smri_t2ww02_cdk_smrh</th>\n",
       "      <th>smri_t2ww02_cdk_fpolerh</th>\n",
       "      <th>smri_t2ww02_cdk_tmpolerh</th>\n",
       "      <th>smri_t2ww02_cdk_tvtmrh</th>\n",
       "      <th>smri_t2ww02_cdk_insularh</th>\n",
       "      <th>smri_t2ww02_cdk_meanlh</th>\n",
       "      <th>smri_t2ww02_cdk_meanrh</th>\n",
       "      <th>smri_t2ww02_cdk_mean</th>\n",
       "      <th>kbi_sex_assigned_at_birth</th>\n",
       "      <th>kbi_sex_assigned_at_birth_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NDAR_INV003RTV85</td>\n",
       "      <td>10/01/2018</td>\n",
       "      <td>baseline_year_1_arm_1</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.647469</td>\n",
       "      <td>0.458583</td>\n",
       "      <td>0.507141</td>\n",
       "      <td>0.349996</td>\n",
       "      <td>0.575188</td>\n",
       "      <td>0.356426</td>\n",
       "      <td>...</td>\n",
       "      <td>127.719801</td>\n",
       "      <td>133.343722</td>\n",
       "      <td>127.464053</td>\n",
       "      <td>131.781973</td>\n",
       "      <td>135.007102</td>\n",
       "      <td>130.321732</td>\n",
       "      <td>129.259147</td>\n",
       "      <td>129.793951</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NDAR_INV00J52GPG</td>\n",
       "      <td>09/05/2018</td>\n",
       "      <td>baseline_year_1_arm_1</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.415813</td>\n",
       "      <td>0.345856</td>\n",
       "      <td>0.426812</td>\n",
       "      <td>0.419386</td>\n",
       "      <td>0.406527</td>\n",
       "      <td>0.307107</td>\n",
       "      <td>...</td>\n",
       "      <td>129.631017</td>\n",
       "      <td>130.780832</td>\n",
       "      <td>131.304128</td>\n",
       "      <td>130.122385</td>\n",
       "      <td>137.059064</td>\n",
       "      <td>131.338717</td>\n",
       "      <td>130.737556</td>\n",
       "      <td>131.039779</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NDAR_INV00LH735Y</td>\n",
       "      <td>01/29/2018</td>\n",
       "      <td>baseline_year_1_arm_1</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.581733</td>\n",
       "      <td>0.246580</td>\n",
       "      <td>0.419327</td>\n",
       "      <td>0.437370</td>\n",
       "      <td>0.440676</td>\n",
       "      <td>0.269801</td>\n",
       "      <td>...</td>\n",
       "      <td>134.650803</td>\n",
       "      <td>138.958301</td>\n",
       "      <td>130.450556</td>\n",
       "      <td>134.234003</td>\n",
       "      <td>143.198841</td>\n",
       "      <td>136.358482</td>\n",
       "      <td>135.535478</td>\n",
       "      <td>135.945715</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NDAR_INV00LJVZK2</td>\n",
       "      <td>08/19/2017</td>\n",
       "      <td>baseline_year_1_arm_1</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0.328469</td>\n",
       "      <td>0.336376</td>\n",
       "      <td>0.552241</td>\n",
       "      <td>0.659492</td>\n",
       "      <td>0.425740</td>\n",
       "      <td>0.462350</td>\n",
       "      <td>...</td>\n",
       "      <td>136.554975</td>\n",
       "      <td>133.116768</td>\n",
       "      <td>141.297444</td>\n",
       "      <td>141.343225</td>\n",
       "      <td>145.048321</td>\n",
       "      <td>138.061447</td>\n",
       "      <td>139.400439</td>\n",
       "      <td>138.732184</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NDAR_INV00R4TXET</td>\n",
       "      <td>04/10/2018</td>\n",
       "      <td>baseline_year_1_arm_1</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.529974</td>\n",
       "      <td>0.393989</td>\n",
       "      <td>0.508073</td>\n",
       "      <td>0.539767</td>\n",
       "      <td>0.377943</td>\n",
       "      <td>0.413167</td>\n",
       "      <td>...</td>\n",
       "      <td>127.580653</td>\n",
       "      <td>136.976903</td>\n",
       "      <td>130.274707</td>\n",
       "      <td>125.604393</td>\n",
       "      <td>135.417724</td>\n",
       "      <td>128.301393</td>\n",
       "      <td>127.861643</td>\n",
       "      <td>128.082384</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 743 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     src_subject_id interview_date              eventname  interview_age  \\\n",
       "0  NDAR_INV003RTV85     10/01/2018  baseline_year_1_arm_1          131.0   \n",
       "4  NDAR_INV00J52GPG     09/05/2018  baseline_year_1_arm_1          110.0   \n",
       "5  NDAR_INV00LH735Y     01/29/2018  baseline_year_1_arm_1          109.0   \n",
       "6  NDAR_INV00LJVZK2     08/19/2017  baseline_year_1_arm_1          121.0   \n",
       "7  NDAR_INV00R4TXET     04/10/2018  baseline_year_1_arm_1          114.0   \n",
       "\n",
       "   rsfmri_c_ngd_ad_ngd_ad  rsfmri_c_ngd_ad_ngd_cgc  rsfmri_c_ngd_ad_ngd_ca  \\\n",
       "0                0.647469                 0.458583                0.507141   \n",
       "4                0.415813                 0.345856                0.426812   \n",
       "5                0.581733                 0.246580                0.419327   \n",
       "6                0.328469                 0.336376                0.552241   \n",
       "7                0.529974                 0.393989                0.508073   \n",
       "\n",
       "   rsfmri_c_ngd_ad_ngd_dt  rsfmri_c_ngd_ad_ngd_dla  rsfmri_c_ngd_ad_ngd_fo  \\\n",
       "0                0.349996                 0.575188                0.356426   \n",
       "4                0.419386                 0.406527                0.307107   \n",
       "5                0.437370                 0.440676                0.269801   \n",
       "6                0.659492                 0.425740                0.462350   \n",
       "7                0.539767                 0.377943                0.413167   \n",
       "\n",
       "   ...  smri_t2ww02_cdk_smrh  smri_t2ww02_cdk_fpolerh  \\\n",
       "0  ...            127.719801               133.343722   \n",
       "4  ...            129.631017               130.780832   \n",
       "5  ...            134.650803               138.958301   \n",
       "6  ...            136.554975               133.116768   \n",
       "7  ...            127.580653               136.976903   \n",
       "\n",
       "   smri_t2ww02_cdk_tmpolerh  smri_t2ww02_cdk_tvtmrh  smri_t2ww02_cdk_insularh  \\\n",
       "0                127.464053              131.781973                135.007102   \n",
       "4                131.304128              130.122385                137.059064   \n",
       "5                130.450556              134.234003                143.198841   \n",
       "6                141.297444              141.343225                145.048321   \n",
       "7                130.274707              125.604393                135.417724   \n",
       "\n",
       "   smri_t2ww02_cdk_meanlh  smri_t2ww02_cdk_meanrh  smri_t2ww02_cdk_mean  \\\n",
       "0              130.321732              129.259147            129.793951   \n",
       "4              131.338717              130.737556            131.039779   \n",
       "5              136.358482              135.535478            135.945715   \n",
       "6              138.061447              139.400439            138.732184   \n",
       "7              128.301393              127.861643            128.082384   \n",
       "\n",
       "   kbi_sex_assigned_at_birth  kbi_sex_assigned_at_birth_norm  \n",
       "0                        2.0                             1.0  \n",
       "4                        1.0                             0.0  \n",
       "5                        1.0                             0.0  \n",
       "6                        1.0                             0.0  \n",
       "7                        2.0                             1.0  \n",
       "\n",
       "[5 rows x 743 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modify\n",
    "config = {'target_col': 'kbi_sex_assigned_at_birth',\n",
    "          'features': ['fmri', 'smri'],\n",
    "          'model': ['abcd.models.regression.MLPRegressor', 'LinearRegressor'],\n",
    "          'lr': 1e-2,\n",
    "          'batch_size': 64,\n",
    "          'nr_epochs': 150\n",
    "        }\n",
    "\n",
    "#leave unmodified\n",
    "experiment_title = 'ABCD_sex_' + config['model'][1] + \"_\" + datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") #for saving results\n",
    "models_path = os.path.join(output_path, experiment_title, 'models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegressor(\n",
      "  (sigmoid): Sigmoid()\n",
      "  (linear1): Linear(in_features=453, out_features=1, bias=True)\n",
      "  (linear_layers): Linear(in_features=453, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/150 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "train MSELoss: 1.033 MSE: 1.033 MAE: 0.882 accuracy: 0.998\n",
      "val MSELoss: 1.029 MSE: 1.027 MAE: 0.879 accuracy: 0.997\n",
      "test MSELoss: 1.061 MSE: 1.052 MAE: 0.893 accuracy: 1.000\n",
      "\n",
      "New best model.\n",
      "\n",
      "Saved PyTorch model state LinearRegressor_epoch0.pth in /Users/carolinezanze/Desktop/abcd5_output/ABCD_sex_LinearRegressor_2023-08-29 01:34:15/models\n",
      "Saved trainer state RegressorTrainer_optimizer_epoch0.pth in /Users/carolinezanze/Desktop/abcd5_output/ABCD_sex_LinearRegressor_2023-08-29 01:34:15/results/states\n",
      "Progress stored in /Users/carolinezanze/Desktop/abcd5_output/ABCD_sex_LinearRegressor_2023-08-29 01:34:15/results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/150 [00:00<00:33,  4.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ending epoch 1, loss 0.4878219532537031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 13/150 [00:01<00:09, 13.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\n",
      "train MSELoss: 0.482 MSE: 0.483 MAE: 0.483 accuracy: 1.000\n",
      "val MSELoss: 0.480 MSE: 0.480 MAE: 0.480 accuracy: 1.000\n",
      "test MSELoss: 0.498 MSE: 0.493 MAE: 0.493 accuracy: 1.000\n",
      "\n",
      "New best model.\n",
      "\n",
      "Ending epoch 11, loss 0.48274108982300973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 23/150 [00:01<00:08, 14.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20\n",
      "train MSELoss: 0.483 MSE: 0.483 MAE: 0.483 accuracy: 1.000\n",
      "val MSELoss: 0.480 MSE: 0.480 MAE: 0.480 accuracy: 1.000\n",
      "test MSELoss: 0.498 MSE: 0.493 MAE: 0.493 accuracy: 1.000\n",
      "\n",
      "New best model.\n",
      "\n",
      "Ending epoch 21, loss 0.48299201034210826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 33/150 [00:02<00:08, 13.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30\n",
      "train MSELoss: 0.482 MSE: 0.483 MAE: 0.483 accuracy: 1.000\n",
      "val MSELoss: 0.480 MSE: 0.480 MAE: 0.480 accuracy: 1.000\n",
      "test MSELoss: 0.498 MSE: 0.493 MAE: 0.493 accuracy: 1.000\n",
      "\n",
      "New best model.\n",
      "\n",
      "Ending epoch 31, loss 0.482741052234495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 43/150 [00:03<00:07, 13.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40\n",
      "train MSELoss: 0.483 MSE: 0.483 MAE: 0.483 accuracy: 1.000\n",
      "val MSELoss: 0.480 MSE: 0.480 MAE: 0.480 accuracy: 1.000\n",
      "test MSELoss: 0.498 MSE: 0.493 MAE: 0.493 accuracy: 1.000\n",
      "Ending epoch 41, loss 0.48249008607220006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 51/150 [00:03<00:07, 12.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50\n",
      "train MSELoss: 0.483 MSE: 0.483 MAE: 0.483 accuracy: 1.000\n",
      "val MSELoss: 0.480 MSE: 0.480 MAE: 0.480 accuracy: 1.000\n",
      "test MSELoss: 0.498 MSE: 0.493 MAE: 0.493 accuracy: 1.000\n",
      "\n",
      "New best model.\n",
      "\n",
      "Saved PyTorch model state LinearRegressor_epoch50.pth in /Users/carolinezanze/Desktop/abcd5_output/ABCD_sex_LinearRegressor_2023-08-29 01:34:15/models\n",
      "Saved trainer state RegressorTrainer_optimizer_epoch50.pth in /Users/carolinezanze/Desktop/abcd5_output/ABCD_sex_LinearRegressor_2023-08-29 01:34:15/results/states\n",
      "Progress stored in /Users/carolinezanze/Desktop/abcd5_output/ABCD_sex_LinearRegressor_2023-08-29 01:34:15/results\n",
      "Ending epoch 51, loss 0.4829919142229063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 63/150 [00:04<00:05, 15.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60\n",
      "train MSELoss: 0.481 MSE: 0.483 MAE: 0.483 accuracy: 1.000\n",
      "val MSELoss: 0.480 MSE: 0.480 MAE: 0.480 accuracy: 1.000\n",
      "test MSELoss: 0.498 MSE: 0.493 MAE: 0.493 accuracy: 1.000\n",
      "Ending epoch 61, loss 0.48223908876513577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 71/150 [00:04<00:05, 14.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70\n",
      "train MSELoss: 0.482 MSE: 0.483 MAE: 0.483 accuracy: 1.000\n",
      "val MSELoss: 0.480 MSE: 0.480 MAE: 0.480 accuracy: 1.000\n",
      "test MSELoss: 0.498 MSE: 0.493 MAE: 0.493 accuracy: 1.000\n",
      "\n",
      "New best model.\n",
      "\n",
      "Ending epoch 71, loss 0.4807334719477473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 83/150 [00:05<00:04, 14.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80\n",
      "train MSELoss: 0.482 MSE: 0.483 MAE: 0.483 accuracy: 1.000\n",
      "val MSELoss: 0.480 MSE: 0.480 MAE: 0.480 accuracy: 1.000\n",
      "test MSELoss: 0.498 MSE: 0.493 MAE: 0.493 accuracy: 1.000\n",
      "Ending epoch 81, loss 0.4829918277693224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 93/150 [00:06<00:03, 15.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90\n",
      "train MSELoss: 0.483 MSE: 0.483 MAE: 0.483 accuracy: 1.000\n",
      "val MSELoss: 0.480 MSE: 0.480 MAE: 0.480 accuracy: 1.000\n",
      "test MSELoss: 0.498 MSE: 0.493 MAE: 0.493 accuracy: 1.000\n",
      "Ending epoch 91, loss 0.4819881024661365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▊   | 103/150 [00:07<00:03, 14.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100\n",
      "train MSELoss: 0.482 MSE: 0.483 MAE: 0.483 accuracy: 1.000\n",
      "val MSELoss: 0.480 MSE: 0.480 MAE: 0.480 accuracy: 1.000\n",
      "test MSELoss: 0.498 MSE: 0.493 MAE: 0.493 accuracy: 1.000\n",
      "Saved PyTorch model state LinearRegressor_epoch100.pth in /Users/carolinezanze/Desktop/abcd5_output/ABCD_sex_LinearRegressor_2023-08-29 01:34:15/models\n",
      "Saved trainer state RegressorTrainer_optimizer_epoch100.pth in /Users/carolinezanze/Desktop/abcd5_output/ABCD_sex_LinearRegressor_2023-08-29 01:34:15/results/states\n",
      "Progress stored in /Users/carolinezanze/Desktop/abcd5_output/ABCD_sex_LinearRegressor_2023-08-29 01:34:15/results\n",
      "Ending epoch 101, loss 0.48223903238236365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 113/150 [00:07<00:02, 14.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110\n",
      "train MSELoss: 0.482 MSE: 0.483 MAE: 0.483 accuracy: 1.000\n",
      "val MSELoss: 0.480 MSE: 0.480 MAE: 0.480 accuracy: 1.000\n",
      "test MSELoss: 0.498 MSE: 0.493 MAE: 0.493 accuracy: 1.000\n",
      "Ending epoch 111, loss 0.48223903238236365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 123/150 [00:08<00:01, 15.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120\n",
      "train MSELoss: 0.481 MSE: 0.483 MAE: 0.483 accuracy: 1.000\n",
      "val MSELoss: 0.480 MSE: 0.480 MAE: 0.480 accuracy: 1.000\n",
      "test MSELoss: 0.498 MSE: 0.493 MAE: 0.493 accuracy: 1.000\n",
      "Ending epoch 121, loss 0.48248996283556966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 133/150 [00:08<00:01, 15.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130\n",
      "train MSELoss: 0.483 MSE: 0.483 MAE: 0.483 accuracy: 1.000\n",
      "val MSELoss: 0.480 MSE: 0.480 MAE: 0.480 accuracy: 1.000\n",
      "test MSELoss: 0.498 MSE: 0.493 MAE: 0.493 accuracy: 1.000\n",
      "Ending epoch 131, loss 0.48248996283556966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 143/150 [00:09<00:00, 15.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140\n",
      "train MSELoss: 0.481 MSE: 0.483 MAE: 0.483 accuracy: 1.000\n",
      "val MSELoss: 0.480 MSE: 0.480 MAE: 0.480 accuracy: 1.000\n",
      "test MSELoss: 0.498 MSE: 0.493 MAE: 0.493 accuracy: 1.000\n",
      "Ending epoch 141, loss 0.4827408930202862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:10<00:00, 14.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training\n",
      "Epoch 150\n",
      "train MSELoss: 0.483 MSE: 0.483 MAE: 0.483 accuracy: 1.000\n",
      "val MSELoss: 0.480 MSE: 0.480 MAE: 0.480 accuracy: 1.000\n",
      "test MSELoss: 0.498 MSE: 0.493 MAE: 0.493 accuracy: 1.000\n",
      "Saved PyTorch model state LinearRegressor_epoch150.pth in /Users/carolinezanze/Desktop/abcd5_output/ABCD_sex_LinearRegressor_2023-08-29 01:34:15/models\n",
      "Saved trainer state RegressorTrainer_optimizer_epoch150.pth in /Users/carolinezanze/Desktop/abcd5_output/ABCD_sex_LinearRegressor_2023-08-29 01:34:15/results/states\n",
      "Progress stored in /Users/carolinezanze/Desktop/abcd5_output/ABCD_sex_LinearRegressor_2023-08-29 01:34:15/results\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (1, 1), indices imply (1, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(model)\n\u001b[1;32m      5\u001b[0m trainer \u001b[39m=\u001b[39m train_model(model, device, config, experiment_title, dataloaders, verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, bucketing_scheme\u001b[39m=\u001b[39mbucketing_scheme)\n\u001b[0;32m----> 6\u001b[0m best_model_details \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mexport_best_model(config\u001b[39m=\u001b[39;49mconfig)\n",
      "File \u001b[0;32m~/Desktop/ABCD5/abcd/training/RegressorTrainer.py:116\u001b[0m, in \u001b[0;36mRegressorTrainer.export_best_model\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_model_details[\u001b[39m'\u001b[39m\u001b[39mcms\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[1;32m    115\u001b[0m         cm \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_model_details[\u001b[39m'\u001b[39m\u001b[39mcms\u001b[39m\u001b[39m'\u001b[39m][key]\n\u001b[0;32m--> 116\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mplot_confusion_matrix(cm, file_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mCM_best_model_\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mformat(key), path\u001b[39m=\u001b[39;49mos\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(best_model_dir))\n\u001b[1;32m    118\u001b[0m \u001b[39m# save model details to .txt file\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(best_model_dir, \u001b[39m\"\u001b[39m\u001b[39mbest_model_details.txt\u001b[39m\u001b[39m\"\u001b[39m), \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/Desktop/ABCD5/abcd/training/RegressorTrainer.py:140\u001b[0m, in \u001b[0;36mRegressorTrainer.plot_confusion_matrix\u001b[0;34m(self, cm, file_name, path)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot_confusion_matrix\u001b[39m(\u001b[39mself\u001b[39m, cm, file_name, path\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    139\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m path: path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer_path\n\u001b[0;32m--> 140\u001b[0m     plot \u001b[39m=\u001b[39m plot_confusion_matrix(cm, labels\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_names, figure_size\u001b[39m=\u001b[39;49m(\u001b[39m12\u001b[39;49m,\u001b[39m10\u001b[39;49m))\n\u001b[1;32m    141\u001b[0m     path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(path, \u001b[39m'\u001b[39m\u001b[39mconfusion_matrices\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    142\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(path):\n",
      "File \u001b[0;32m~/Desktop/ABCD5/abcd/plotting/seaborn/confusion_matrix.py:12\u001b[0m, in \u001b[0;36mplot_confusion_matrix\u001b[0;34m(cm, labels, figure_size, vmin, vmax, cmap, title)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot_confusion_matrix\u001b[39m(cm, labels\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, figure_size\u001b[39m=\u001b[39m(\u001b[39m5.25\u001b[39m,\u001b[39m3.75\u001b[39m), vmin\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, vmax\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, cmap\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, title\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m     10\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Receives a confusion matrix where the in the first dimension are the true classes and in the\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39m    second, what they were predicted as. For instance cm[0] are the values for the true class 0'''\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame(cm, columns\u001b[39m=\u001b[39;49mlabels)\n\u001b[1;32m     13\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m         labels \u001b[39m=\u001b[39m [\u001b[39mstr\u001b[39m(ix) \u001b[39mfor\u001b[39;00m ix \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(cm))]\n",
      "File \u001b[0;32m~/anaconda3/envs/cns/lib/python3.11/site-packages/pandas/core/frame.py:758\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    747\u001b[0m         mgr \u001b[39m=\u001b[39m dict_to_mgr(\n\u001b[1;32m    748\u001b[0m             \u001b[39m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[1;32m    749\u001b[0m             \u001b[39m# attribute \"name\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    755\u001b[0m             copy\u001b[39m=\u001b[39m_copy,\n\u001b[1;32m    756\u001b[0m         )\n\u001b[1;32m    757\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 758\u001b[0m         mgr \u001b[39m=\u001b[39m ndarray_to_mgr(\n\u001b[1;32m    759\u001b[0m             data,\n\u001b[1;32m    760\u001b[0m             index,\n\u001b[1;32m    761\u001b[0m             columns,\n\u001b[1;32m    762\u001b[0m             dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    763\u001b[0m             copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m    764\u001b[0m             typ\u001b[39m=\u001b[39;49mmanager,\n\u001b[1;32m    765\u001b[0m         )\n\u001b[1;32m    767\u001b[0m \u001b[39m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[1;32m    768\u001b[0m \u001b[39melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[0;32m~/anaconda3/envs/cns/lib/python3.11/site-packages/pandas/core/internals/construction.py:337\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[39m# _prep_ndarraylike ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[1;32m    333\u001b[0m index, columns \u001b[39m=\u001b[39m _get_axes(\n\u001b[1;32m    334\u001b[0m     values\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], values\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], index\u001b[39m=\u001b[39mindex, columns\u001b[39m=\u001b[39mcolumns\n\u001b[1;32m    335\u001b[0m )\n\u001b[0;32m--> 337\u001b[0m _check_values_indices_shape_match(values, index, columns)\n\u001b[1;32m    339\u001b[0m \u001b[39mif\u001b[39;00m typ \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39marray\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    340\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(values\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype, \u001b[39mstr\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/cns/lib/python3.11/site-packages/pandas/core/internals/construction.py:408\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[0;34m(values, index, columns)\u001b[0m\n\u001b[1;32m    406\u001b[0m passed \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mshape\n\u001b[1;32m    407\u001b[0m implied \u001b[39m=\u001b[39m (\u001b[39mlen\u001b[39m(index), \u001b[39mlen\u001b[39m(columns))\n\u001b[0;32m--> 408\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mShape of passed values is \u001b[39m\u001b[39m{\u001b[39;00mpassed\u001b[39m}\u001b[39;00m\u001b[39m, indices imply \u001b[39m\u001b[39m{\u001b[39;00mimplied\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (1, 1), indices imply (1, 2)"
     ]
    }
   ],
   "source": [
    "model = LinearRegressor(save_path=models_path, input_size=len(feature_cols)) #modfiy\n",
    "\n",
    "model = model.to(device)\n",
    "print(model)\n",
    "trainer = train_model(model, device, config, experiment_title, dataloaders, verbose=True, bucketing_scheme=bucketing_scheme)\n",
    "best_model_details = trainer.export_best_model(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modify\n",
    "experiment_title = 'sex_MLPReg_' + datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") #for saving results\n",
    "print(experiment_title)\n",
    "\n",
    "config = {'target_col': 'kbi_sex_assigned_at_birth',\n",
    "          'features': ['fmri', 'smri'],\n",
    "          'model': ['abcd.models.regression.MLPRegressor', 'MLPRegressorCustom'],\n",
    "          'batch_size': 64,\n",
    "\n",
    "          #tune\n",
    "          'lr': 1e-3,\n",
    "          'nr_epochs': 150,\n",
    "          'hidden_sizes': [256, 64]\n",
    "        }\n",
    "\n",
    "#leave unmodified\n",
    "models_path = os.path.join(output_path, experiment_title, 'models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPRegressorCustom(save_path=models_path, input_size=len(feature_cols), hidden_sizes=config['hidden_sizes']) #modfiy\n",
    "\n",
    "model = model.to(device)\n",
    "print(model)\n",
    "trainer = train_model(model, device, config, experiment_title, dataloaders, verbose=True, bucketing_scheme=bucketing_scheme)\n",
    "trainer.export_best_model(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Search with Cusom MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_sizes = [\n",
    "    (128, 64),\n",
    "    (256, 128, 64), \n",
    "    (512, 256, 128, 64),\n",
    "]\n",
    "\n",
    "learning_rates = [1e-3, 1e-5, 1e-7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = {}\n",
    "global_best_val_mse = float('inf')\n",
    "best_model_experiment_name = None\n",
    "best_model = None\n",
    "\n",
    "for i,learning_rate in enumerate(learning_rates):\n",
    "    for j,sizes in enumerate(hidden_sizes):\n",
    "        experiment_title = 'sex_MLPReg_' + datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        experiment_num = i*len(hidden_sizes) + j\n",
    "        print(\"experiment\", experiment_num, \":\", experiment_title)\n",
    "\n",
    "        config = {'target_col': 'kbi_sex_assigned_at_birth',\n",
    "          'features': ['fmri', 'smri'],\n",
    "          'model': ['abcd.models.regression.MLPRegressor', 'MLPRegressorCustom'],\n",
    "          'batch_size': 64,\n",
    "          'nr_epochs': 250,\n",
    "\n",
    "          #tune\n",
    "          'lr': 1e-3,\n",
    "          'hidden_sizes': [256, 64]\n",
    "        }\n",
    "\n",
    "        config['hidden_sizes'] = sizes\n",
    "        config['lr'] = learning_rate\n",
    "\n",
    "        #define and train model\n",
    "        models_path = os.path.join(output_path, experiment_title, 'models')\n",
    "        model = MLPRegressorCustom(save_path=models_path, input_size=len(feature_cols), hidden_sizes=config['hidden_sizes']) #modfiy\n",
    "        model = model.to(device)\n",
    "        trainer = train_model(model, device, config, experiment_title, dataloaders, verbose=False, bucketing_scheme=bucketing_scheme)\n",
    "        details = trainer.export_best_model(config=config)\n",
    "        \n",
    "        #update best model\n",
    "        local_best_val_mse = details['metrics']['val']['MSE']\n",
    "        if local_best_val_mse < global_best_val_mse:\n",
    "            global_best_val_mse = local_best_val_mse\n",
    "            best_model = details\n",
    "            best_model_experiment_name = experiment_title\n",
    "\n",
    "        #save experiment\n",
    "        experiments[experiment_title] = details\n",
    "\n",
    "print(\"\\n\\nExperiment over. Best model:\", best_model_experiment_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cns",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
